#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨å¤šSheetæ•°æ®åˆ†æå·¥å…·
ä¸“é—¨åˆ†æåˆå¹¶åçš„Excelæ–‡ä»¶ï¼Œæä¾›å…¨é¢çš„æ•°æ®æ´å¯Ÿå’Œåˆ†ææŠ¥å‘Š
"""

import os
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ====== é…ç½®åŒºåŸŸ ======

# è¾“å…¥æ–‡ä»¶é…ç½®
EXCEL_FILES = [
    "æ•°æ®åˆå¹¶ç»“æœ_20250601_1703.xlsx",  # æœ€æ–°åˆå¹¶æ–‡ä»¶
    "å®Œæ•´é‡‘èæ•°æ®åˆå¹¶_20250601_1658.xlsx",  # å®Œæ•´é‡‘èæ•°æ®
    "å¤šè¡¨åˆå¹¶æ•°æ®_20250601_1658.xlsx",  # å¤šè¡¨åˆå¹¶æ•°æ®
]

# è¾“å‡ºé…ç½®
ANALYSIS_OUTPUT_DIR = "åˆ†æç»“æœ"

# ====== é…ç½®åŒºåŸŸç»“æŸ ======


class AutoMultiSheetAnalyzer:
    """è‡ªåŠ¨å¤šSheetæ•°æ®åˆ†æå™¨"""
    
    def __init__(self, excel_file):
        self.excel_file = excel_file
        self.sheets_data = {}
        self.summary_info = {}
        self.analysis_results = {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(ANALYSIS_OUTPUT_DIR, exist_ok=True)
        
    def load_excel_data(self):
        """åŠ è½½Excelæ–‡ä»¶çš„æ‰€æœ‰Sheetæ•°æ®"""
        print(f"ğŸ“– æ­£åœ¨åŠ è½½Excelæ–‡ä»¶: {self.excel_file}")
        
        try:
            # è·å–æ‰€æœ‰Sheetåç§°
            excel_file = pd.ExcelFile(self.excel_file)
            sheet_names = excel_file.sheet_names
            
            print(f"   ğŸ“Š å‘ç° {len(sheet_names)} ä¸ªSheet")
            
            # è¯»å–æ¯ä¸ªSheetï¼ˆé™åˆ¶å‰50ä¸ªSheetä»¥æé«˜é€Ÿåº¦ï¼‰
            for i, sheet_name in enumerate(sheet_names[:50], 1):
                try:
                    print(f"   [{i}/{min(50, len(sheet_names))}] è¯»å–Sheet: {sheet_name}")
                    
                    df = pd.read_excel(self.excel_file, sheet_name=sheet_name)
                    
                    # è¿‡æ»¤æ‰å…ƒä¿¡æ¯è¡Œï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if 'å…ƒä¿¡æ¯' in df.columns or 'æ–‡ä»¶ä¿¡æ¯' in df.columns:
                        # æ‰¾åˆ°å…ƒä¿¡æ¯å¼€å§‹çš„ä½ç½®
                        meta_start = None
                        for idx, row in df.iterrows():
                            if 'åŸå§‹æ–‡ä»¶å' in str(row.values):
                                meta_start = idx
                                break
                        
                        if meta_start is not None:
                            df = df.iloc[:meta_start]  # åªä¿ç•™æ•°æ®éƒ¨åˆ†
                    
                    self.sheets_data[sheet_name] = df
                    print(f"      âœ… æˆåŠŸè¯»å–: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
                    
                except Exception as e:
                    print(f"      âŒ è¯»å–å¤±è´¥: {str(e)}")
                    continue
            
            if len(sheet_names) > 50:
                print(f"   ğŸ“‹ æ³¨æ„: ä¸ºæé«˜åˆ†æé€Ÿåº¦ï¼Œåªåˆ†æå‰50ä¸ªSheetï¼ˆæ€»å…±{len(sheet_names)}ä¸ªï¼‰")
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.sheets_data)} ä¸ªSheetçš„æ•°æ®")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½Excelæ–‡ä»¶å¤±è´¥: {str(e)}")
            return False
    
    def analyze_data_overview(self):
        """æ•°æ®æ¦‚è§ˆåˆ†æ"""
        print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆåˆ†æ")
        print("-" * 50)
        
        total_rows = 0
        sheet_info = []
        
        for sheet_name, df in self.sheets_data.items():
            if sheet_name == 'ğŸ“Šæ±‡æ€»ä¿¡æ¯':  # è·³è¿‡æ±‡æ€»Sheet
                continue
                
            rows = len(df)
            cols = len(df.columns)
            total_rows += rows
            
            sheet_info.append({
                'sheet_name': sheet_name,
                'rows': rows,
                'columns': cols,
                'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024,
                'non_null_ratio': df.count().sum() / (rows * cols) if rows * cols > 0 else 0
            })
        
        # æ’åºï¼šæŒ‰è¡Œæ•°æ’åº
        sheet_info.sort(key=lambda x: x['rows'], reverse=True)
        
        print(f"æ•°æ®é›†æ€»è§ˆ:")
        print(f"   ğŸ“„ æ€»Sheetæ•°: {len(sheet_info)}")
        print(f"   ğŸ“ˆ æ€»æ•°æ®è¡Œæ•°: {total_rows:,}")
        print(f"   ğŸ’¾ æ€»å†…å­˜å ç”¨: {sum(info['memory_usage_mb'] for info in sheet_info):.1f} MB")
        
        print(f"\nğŸ“‹ å„Sheetè¯¦ç»†ä¿¡æ¯ï¼ˆæŒ‰æ•°æ®é‡æ’åºï¼‰:")
        print(f"{'Sheetåç§°':<35} {'è¡Œæ•°':<10} {'åˆ—æ•°':<8} {'å®Œæ•´åº¦':<10}")
        print("-" * 70)
        
        for info in sheet_info[:15]:  # æ˜¾ç¤ºå‰15ä¸ªæœ€å¤§çš„Sheet
            completeness = f"{info['non_null_ratio']*100:.1f}%"
            print(f"{info['sheet_name']:<35} {info['rows']:<10,} {info['columns']:<8} {completeness:<10}")
        
        if len(sheet_info) > 15:
            print(f"... è¿˜æœ‰ {len(sheet_info) - 15} ä¸ªSheet")
        
        self.analysis_results['overview'] = {
            'total_sheets': len(sheet_info),
            'total_rows': total_rows,
            'sheet_info': sheet_info
        }
        
        return sheet_info
    
    def analyze_data_types(self):
        """æ•°æ®ç±»å‹åˆ†æ"""
        print(f"\nğŸ” æ•°æ®ç±»å‹åˆ†æ")
        print("-" * 50)
        
        all_numeric_cols = set()
        all_text_cols = set()
        all_date_cols = set()
        common_columns = None
        
        for sheet_name, df in self.sheets_data.items():
            if sheet_name == 'ğŸ“Šæ±‡æ€»ä¿¡æ¯':
                continue
            
            # åˆ†æåˆ—ç±»å‹
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            text_cols = df.select_dtypes(include=['object']).columns.tolist()
            date_cols = df.select_dtypes(include=['datetime']).columns.tolist()
            
            # å°è¯•è¯†åˆ«å¯èƒ½çš„æ—¥æœŸåˆ—
            potential_date_cols = []
            for col in text_cols:
                if any(keyword in col.lower() for keyword in ['date', 'æ—¥æœŸ', 'time', 'æ—¶é—´', 'å¹´', 'æœˆ', 'æ—¥']):
                    potential_date_cols.append(col)
            
            all_numeric_cols.update(numeric_cols)
            all_text_cols.update(text_cols)
            all_date_cols.update(date_cols + potential_date_cols)
            
            # æ‰¾å‡ºå…±åŒåˆ—
            if common_columns is None:
                common_columns = set(df.columns)
            else:
                common_columns = common_columns.intersection(set(df.columns))
        
        print(f"æ•°æ®ç±»å‹ç»Ÿè®¡:")
        print(f"   ğŸ”¢ æ•°å€¼å‹åˆ—: {len(all_numeric_cols)} ä¸ª")
        print(f"   ğŸ“ æ–‡æœ¬å‹åˆ—: {len(all_text_cols)} ä¸ª")
        print(f"   ğŸ“… æ—¥æœŸå‹åˆ—: {len(all_date_cols)} ä¸ª")
        print(f"   ğŸ”— å…±åŒåˆ—: {len(common_columns)} ä¸ª")
        
        if len(common_columns) > 0:
            print(f"\nå…±åŒåˆ—å (å‰10ä¸ª):")
            for col in sorted(list(common_columns))[:10]:
                print(f"   - {col}")
            if len(common_columns) > 10:
                print(f"   ... è¿˜æœ‰ {len(common_columns) - 10} ä¸ª")
        
        # æ˜¾ç¤ºä¸»è¦æ•°å€¼åˆ—
        if len(all_numeric_cols) > 0:
            print(f"\nä¸»è¦æ•°å€¼åˆ— (å‰10ä¸ª):")
            for col in sorted(list(all_numeric_cols))[:10]:
                print(f"   - {col}")
        
        self.analysis_results['data_types'] = {
            'numeric_columns': list(all_numeric_cols),
            'text_columns': list(all_text_cols),
            'date_columns': list(all_date_cols),
            'common_columns': list(common_columns)
        }
        
        return all_numeric_cols, all_text_cols, all_date_cols, common_columns
    
    def analyze_data_quality(self):
        """æ•°æ®è´¨é‡åˆ†æ"""
        print(f"\nğŸ¯ æ•°æ®è´¨é‡åˆ†æ")
        print("-" * 50)
        
        quality_report = []
        
        for sheet_name, df in self.sheets_data.items():
            if sheet_name == 'ğŸ“Šæ±‡æ€»ä¿¡æ¯':
                continue
            
            # è®¡ç®—å„ç§è´¨é‡æŒ‡æ ‡
            total_cells = len(df) * len(df.columns)
            null_cells = df.isnull().sum().sum()
            duplicate_rows = df.duplicated().sum()
            
            quality_info = {
                'sheet_name': sheet_name,
                'total_cells': total_cells,
                'null_cells': null_cells,
                'null_percentage': (null_cells / total_cells * 100) if total_cells > 0 else 0,
                'duplicate_rows': duplicate_rows,
                'duplicate_percentage': (duplicate_rows / len(df) * 100) if len(df) > 0 else 0,
            }
            
            quality_report.append(quality_info)
        
        # æ˜¾ç¤ºè´¨é‡æŠ¥å‘Š
        print(f"æ•°æ®è´¨é‡æŠ¥å‘Š (å‰15ä¸ªSheet):")
        print(f"{'Sheetåç§°':<35} {'ç¼ºå¤±ç‡':<10} {'é‡å¤ç‡':<10} {'æ•°æ®é‡':<10}")
        print("-" * 75)
        
        # æŒ‰ç¼ºå¤±ç‡æ’åº
        quality_report.sort(key=lambda x: x['null_percentage'], reverse=True)
        
        for info in quality_report[:15]:
            null_pct = f"{info['null_percentage']:.1f}%"
            dup_pct = f"{info['duplicate_percentage']:.1f}%"
            data_size = f"{info['total_cells']:,}"
            print(f"{info['sheet_name']:<35} {null_pct:<10} {dup_pct:<10} {data_size:<10}")
        
        # è®¡ç®—æ€»ä½“è´¨é‡ç»Ÿè®¡
        avg_null_rate = np.mean([q['null_percentage'] for q in quality_report])
        avg_dup_rate = np.mean([q['duplicate_percentage'] for q in quality_report])
        
        print(f"\nè´¨é‡æ€»è§ˆ:")
        print(f"   ğŸ“Š å¹³å‡ç¼ºå¤±ç‡: {avg_null_rate:.1f}%")
        print(f"   ğŸ“Š å¹³å‡é‡å¤ç‡: {avg_dup_rate:.1f}%")
        print(f"   ğŸ¯ é«˜è´¨é‡Sheet (ç¼ºå¤±ç‡<10%): {sum(1 for q in quality_report if q['null_percentage'] < 10)} ä¸ª")
        
        self.analysis_results['quality'] = quality_report
        return quality_report
    
    def analyze_numerical_data(self):
        """æ•°å€¼æ•°æ®åˆ†æ"""
        print(f"\nğŸ“ˆ æ•°å€¼æ•°æ®åˆ†æ")
        print("-" * 50)
        
        all_numeric_data = []
        numeric_summary = {}
        
        for sheet_name, df in self.sheets_data.items():
            if sheet_name == 'ğŸ“Šæ±‡æ€»ä¿¡æ¯':
                continue
            
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            if len(numeric_cols) > 0:
                for col in numeric_cols:
                    values = df[col].dropna()
                    if len(values) > 0:
                        all_numeric_data.extend(values)
                        
                        if col not in numeric_summary:
                            numeric_summary[col] = {
                                'total_values': 0,
                                'sum': 0,
                                'min': float('inf'),
                                'max': float('-inf'),
                                'sheets': []
                            }
                        
                        numeric_summary[col]['total_values'] += len(values)
                        numeric_summary[col]['sum'] += values.sum()
                        numeric_summary[col]['min'] = min(numeric_summary[col]['min'], values.min())
                        numeric_summary[col]['max'] = max(numeric_summary[col]['max'], values.max())
                        numeric_summary[col]['sheets'].append(sheet_name)
        
        # æ˜¾ç¤ºæ•°å€¼åˆ†æç»“æœ
        if all_numeric_data:
            print(f"æ•°å€¼æ•°æ®æ¦‚è¿°:")
            print(f"   ğŸ“Š æ€»æ•°å€¼ä¸ªæ•°: {len(all_numeric_data):,}")
            print(f"   ğŸ“ˆ æ•°å€¼èŒƒå›´: {min(all_numeric_data):.2f} ~ {max(all_numeric_data):.2f}")
            print(f"   ğŸ“Š å¹³å‡å€¼: {np.mean(all_numeric_data):.2f}")
            print(f"   ğŸ“Š ä¸­ä½æ•°: {np.median(all_numeric_data):.2f}")
            
            print(f"\nä¸»è¦æ•°å€¼åˆ—åˆ†æ (å‰10ä¸ª):")
            print(f"{'åˆ—å':<25} {'æ€»å€¼æ•°':<10} {'æœ€å°å€¼':<12} {'æœ€å¤§å€¼':<12} {'å¹³å‡å€¼':<12}")
            print("-" * 80)
            
            # æŒ‰æ€»å€¼æ•°æ’åºï¼Œæ˜¾ç¤ºå‰10ä¸ª
            sorted_cols = sorted(numeric_summary.items(), 
                               key=lambda x: x[1]['total_values'], reverse=True)
            
            for col_name, stats in sorted_cols[:10]:
                avg_val = stats['sum'] / stats['total_values']
                print(f"{col_name:<25} {stats['total_values']:<10,} {stats['min']:<12.2f} {stats['max']:<12.2f} {avg_val:<12.2f}")
        
        self.analysis_results['numerical'] = {
            'total_values': len(all_numeric_data),
            'column_summary': numeric_summary
        }
        
        return numeric_summary
    
    def find_key_insights(self):
        """å¯»æ‰¾å…³é”®æ´å¯Ÿ"""
        print(f"\nğŸ” å…³é”®æ´å¯Ÿåˆ†æ")
        print("-" * 50)
        
        insights = []
        
        # 1. è¯†åˆ«æœ€é‡è¦çš„Sheet
        if 'overview' in self.analysis_results:
            sheet_info = self.analysis_results['overview']['sheet_info']
            largest_sheets = sheet_info[:5]
            
            print(f"æ•°æ®é‡æœ€å¤§çš„5ä¸ªSheet:")
            for i, info in enumerate(largest_sheets, 1):
                print(f"   {i}. {info['sheet_name']}: {info['rows']:,} è¡Œ")
        
        # 2. æ•°æ®è´¨é‡é—®é¢˜è¯†åˆ«
        if 'quality' in self.analysis_results:
            quality_data = self.analysis_results['quality']
            problematic_sheets = [q for q in quality_data if q['null_percentage'] > 20]
            
            if problematic_sheets:
                print(f"\næ•°æ®è´¨é‡é—®é¢˜Sheet (ç¼ºå¤±ç‡>20%):")
                for sheet in problematic_sheets[:5]:
                    print(f"   - {sheet['sheet_name']}: ç¼ºå¤±ç‡ {sheet['null_percentage']:.1f}%")
        
        # 3. æ•°å€¼æ•°æ®ç‰¹å¾
        if 'numerical' in self.analysis_results:
            numerical = self.analysis_results['numerical']
            if numerical['total_values'] > 0:
                print(f"\næ•°å€¼æ•°æ®ç‰¹å¾:")
                print(f"   ğŸ“Š å‘ç° {len(numerical['column_summary'])} ä¸ªä¸åŒçš„æ•°å€¼åˆ—")
                print(f"   ğŸ“ˆ æ€»è®¡ {numerical['total_values']:,} ä¸ªæ•°å€¼")
                
                # æ‰¾å‡ºè¦†ç›–æœ€å¹¿çš„æ•°å€¼åˆ—
                top_cols = sorted(numerical['column_summary'].items(), 
                                key=lambda x: x[1]['total_values'], reverse=True)[:3]
                print(f"   ğŸ” è¦†ç›–æœ€å¹¿çš„æ•°å€¼åˆ—:")
                for col, stats in top_cols:
                    print(f"      - {col}: {stats['total_values']:,} ä¸ªå€¼")
        
        return insights
    
    def generate_summary_report(self):
        """ç”Ÿæˆåˆ†ææ€»ç»“æŠ¥å‘Š"""
        print(f"\nğŸ“‹ ç”Ÿæˆåˆ†ææ€»ç»“æŠ¥å‘Š")
        print("-" * 50)
        
        report_file = os.path.join(ANALYSIS_OUTPUT_DIR, f"æ•°æ®åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M')}.txt")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"å¤šSheetæ•°æ®åˆ†ææŠ¥å‘Š\n")
            f.write(f"=" * 50 + "\n")
            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"åˆ†ææ–‡ä»¶: {self.excel_file}\n\n")
            
            # æ•°æ®æ¦‚è§ˆ
            if 'overview' in self.analysis_results:
                overview = self.analysis_results['overview']
                f.write(f"æ•°æ®æ¦‚è§ˆ:\n")
                f.write(f"  æ€»Sheetæ•°: {overview['total_sheets']}\n")
                f.write(f"  æ€»è¡Œæ•°: {overview['total_rows']:,}\n\n")
                
                f.write(f"ä¸»è¦Sheetä¿¡æ¯:\n")
                for info in overview['sheet_info'][:15]:
                    f.write(f"  - {info['sheet_name']}: {info['rows']:,} è¡Œ, {info['columns']} åˆ—\n")
                f.write("\n")
            
            # æ•°æ®è´¨é‡
            if 'quality' in self.analysis_results:
                f.write(f"æ•°æ®è´¨é‡æ‘˜è¦:\n")
                quality_data = self.analysis_results['quality']
                avg_null_rate = np.mean([q['null_percentage'] for q in quality_data])
                avg_dup_rate = np.mean([q['duplicate_percentage'] for q in quality_data])
                f.write(f"  å¹³å‡ç¼ºå¤±ç‡: {avg_null_rate:.1f}%\n")
                f.write(f"  å¹³å‡é‡å¤ç‡: {avg_dup_rate:.1f}%\n")
                f.write(f"  é«˜è´¨é‡Sheetæ•°: {sum(1 for q in quality_data if q['null_percentage'] < 10)}\n\n")
            
            # æ•°å€¼åˆ†æ
            if 'numerical' in self.analysis_results:
                numerical = self.analysis_results['numerical']
                f.write(f"æ•°å€¼æ•°æ®åˆ†æ:\n")
                f.write(f"  æ€»æ•°å€¼ä¸ªæ•°: {numerical['total_values']:,}\n")
                f.write(f"  ä¸»è¦æ•°å€¼åˆ—æ•°: {len(numerical['column_summary'])}\n\n")
            
            # æ•°æ®ç±»å‹
            if 'data_types' in self.analysis_results:
                types = self.analysis_results['data_types']
                f.write(f"æ•°æ®ç±»å‹åˆ†å¸ƒ:\n")
                f.write(f"  æ•°å€¼å‹åˆ—: {len(types['numeric_columns'])}\n")
                f.write(f"  æ–‡æœ¬å‹åˆ—: {len(types['text_columns'])}\n")
                f.write(f"  æ—¥æœŸå‹åˆ—: {len(types['date_columns'])}\n")
                f.write(f"  å…±åŒåˆ—: {len(types['common_columns'])}\n\n")
            
            # å»ºè®®
            f.write(f"åˆ†æå»ºè®®:\n")
            f.write(f"  1. é‡ç‚¹å…³æ³¨æ•°æ®é‡æœ€å¤§çš„Sheetè¿›è¡Œæ·±å…¥åˆ†æ\n")
            f.write(f"  2. å¯¹ç¼ºå¤±ç‡é«˜çš„Sheetè€ƒè™‘æ•°æ®æ¸…æ´—æˆ–è¡¥å…¨\n")
            f.write(f"  3. åˆ©ç”¨å…±åŒåˆ—è¿›è¡Œè·¨Sheetæ•°æ®å…³è”åˆ†æ\n")
            f.write(f"  4. å¯¹æ•°å€¼åˆ—è¿›è¡Œç»Ÿè®¡åˆ†æå’Œè¶‹åŠ¿åˆ†æ\n")
            f.write(f"  5. è€ƒè™‘å°†æ•°æ®è´¨é‡å¥½çš„Sheetç”¨äºæ ¸å¿ƒåˆ†æ\n")
        
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        return report_file
    
    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print(f"ğŸš€ å¼€å§‹å¤šSheetæ•°æ®è‡ªåŠ¨åˆ†æ")
        print(f"åˆ†ææ–‡ä»¶: {self.excel_file}")
        print("=" * 60)
        
        # 1. åŠ è½½æ•°æ®
        if not self.load_excel_data():
            return False
        
        # 2. æ•°æ®æ¦‚è§ˆ
        self.analyze_data_overview()
        
        # 3. æ•°æ®ç±»å‹åˆ†æ
        self.analyze_data_types()
        
        # 4. æ•°æ®è´¨é‡åˆ†æ
        self.analyze_data_quality()
        
        # 5. æ•°å€¼æ•°æ®åˆ†æ
        self.analyze_numerical_data()
        
        # 6. å…³é”®æ´å¯Ÿ
        self.find_key_insights()
        
        # 7. ç”ŸæˆæŠ¥å‘Š
        report_file = self.generate_summary_report()
        
        print(f"\nğŸ‰ åˆ†æå®Œæˆ!")
        print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š è‡ªåŠ¨å¤šSheetæ•°æ®åˆ†æå·¥å…·")
    print("=" * 40)
    
    # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ–‡ä»¶
    target_file = None
    for filename in EXCEL_FILES:
        if os.path.exists(filename):
            file_size = os.path.getsize(filename) / 1024 / 1024
            print(f"ğŸ“ æ‰¾åˆ°åˆ†ææ–‡ä»¶: {filename} ({file_size:.1f} MB)")
            target_file = filename
            break
    
    if not target_file:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯åˆ†æçš„Excelæ–‡ä»¶!")
        return
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œåˆ†æ
    analyzer = AutoMultiSheetAnalyzer(target_file)
    success = analyzer.run_full_analysis()
    
    if success:
        print(f"\nğŸ’¡ åˆ†æç»“æœå·²ä¿å­˜åˆ° '{ANALYSIS_OUTPUT_DIR}' æ–‡ä»¶å¤¹")
    else:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")


if __name__ == "__main__":
    main() 